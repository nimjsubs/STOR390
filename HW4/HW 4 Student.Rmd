---
title: "HW 4"
author: "Nimalan Subramanian"
date: "3/18/2024"
output: 
  html_document:
    number_sections: true
---

This homework is designed to give you practice fitting a logistic regression and working with statistical/philosophical measures of fairness.  We will work with the `titanic` dataset which we have previously seen in class in connection to decision trees.  

Below I will preprocess the data precisely as we did in class.  You can simply refer to `data_train` as your training data and `data_test` as your testing data.  




```{r}

#this is all of the preprocessing done for the decision trees lecture.  

path <- 'https://raw.githubusercontent.com/guru99-edu/R-Programming/master/titanic_data.csv'
titanic <-read.csv(path)
head(titanic)

library(dplyr)

#replace ? with NA
replace_question_mark <- function(x) {
  if (is.character(x)) {
    x <- na_if(x, "?")
  }
  return(x)
}

titanic <- titanic %>%
  mutate_all(replace_question_mark)

set.seed(678)
shuffle_index <- sample(1:nrow(titanic))
head(shuffle_index)

titanic <- titanic[shuffle_index, ]
head(titanic)

library(dplyr)
# Drop variables
clean_titanic <- titanic %>%
select(-c(home.dest, cabin, name, x, ticket)) %>% 
#Convert to factor level
    mutate(pclass = factor(pclass, levels = c(1, 2, 3), labels = c('Upper', 'Middle', 'Lower')),
    survived = factor(survived, levels = c(0, 1), labels = c('No', 'Yes'))) %>%
na.omit()
#previously were characters
clean_titanic$age <- as.numeric(clean_titanic$age)
clean_titanic$fare <- as.numeric(clean_titanic$fare)
glimpse(clean_titanic)

create_train_test <- function(data, size = 0.8, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
data_train <- create_train_test(clean_titanic, 0.8, train = TRUE)
data_test <- create_train_test(clean_titanic, 0.8, train = FALSE)

```

#
Create a table reporting the proportion of people in the training set surviving the Titanic.  Do the same for the testing set.  Comment on whether the current training-testing partition looks suitable.  

```{r}
# Proportion survived in training set
survived_training <- data_train %>%
  group_by(survived) %>%
  summarise(Count = n()) %>%
  mutate(proportion = Count/sum(Count))

# Proportion survived in testing set
survived_testing <- data_test %>%
  group_by(survived) %>%
  summarise(Count = n()) %>%
  mutate(proportion = Count/sum(Count))

survived_training
survived_testing
```

The training set has ~60.19% who did not survive and ~39.81% who did, while the testing set has ~55.50% who did not survive compared to 44.50% who did. There is a slight difference in the proportions between the training and testing sets, but both show that there is a relatively similar distribution of survival outcomes. Since the training set has a higher proportion of non-survivors compared to the testing set, the discrepancy could cause a form of bias by overfitting non-survivors. This should not be too much of an issue, though, as ther difference in proportions between the sets is small enough for the partition to be mostly applicable.

#
Use the `glm` command to build a logistic regression on the training partition.  `survived` should be your response variable and `pclass`, `sex`, `age`, `sibsp`, and `parch` should be your response variables.  

```{r}

#student input
glm_train <- glm(survived ~ pclass + sex + age + sibsp + parch, data = data_train, family = binomial(link = "logit"))
summary(glm_train)
```

We would now like to test whether this classifier is *fair* across the sex subgroups.  It was reported that women and children were prioritized on the life-boats and as a result survived the incident at a much higher rate.  Let us see if our model is able to capture this fact.  

#

Subset your test data into a male group and a female group.  Then, use the `predict` function on the male testing group to come up with predicted probabilities of surviving the Titanic for each male in the testing set.  Do the same for the female testing group.  

```{r}

#student input
male_test <- subset(data_test, sex == "male")
female_test <- subset(data_test, sex == "female")

male_pred <- predict(glm_train, newdata = male_test, type = "response")
female_pred <- predict(glm_train, newdata = female_test, type = "response")

summary(male_pred)
summary(female_pred)
```

# 

Now recall that for this logistic *regression* to be a true classifier, we need to pair it with a decision boundary.  Use an `if-else` statement to translate any predicted probability in the male group greater than $0.5$ into `Yes` (as in Yes this individual is predicted to have survived).  Likewise an predicted probability less than $0.5$ should be translated into a `No`.  

Do this for the female testing group as well, and then create a confusion matrix for each of the male and female test set predictions.  You can use the `confusionMatrix` command as seen in class to expidite this process as well as provide you necessary metrics for the following questions.  

```{r}
library(caret)
#student input
male_pred <- ifelse(male_pred > 0.5, "Yes", "No")
female_pred <- ifelse(female_pred > 0.5, "Yes", "No")

cm_male <- confusionMatrix(as.factor(male_pred), male_test$survived, positive = "Yes")
cm_female <- confusionMatrix(as.factor(female_pred), female_test$survived, positive = "Yes")

cm_male
cm_female
```

#
We can see that indeed, at least within the testing groups, women did seem to survive at a higher proportion than men (24.8\% to 76.3\% in the testing set).  Print a summary of your trained model and interpret one of the fitted coefficients in light of the above disparity.  

```{r}
#student input
summary(glm_train)
```

The variable 'sexmale' has an estimate of -2.684206 based on the model. The negative indicates that being male decreases the log odds of survival compared to females, when all other variables are constant. The large magnitude suggests that sex plays a role on the odds of survival. The small p-value also indicates that the impact of sex on survival is statistically significant, meaning that the observed association between sex and survival is likely not by chance.


#

Now let's see if our model is *fair* across this explanatory variable.  Calculate five measures (as defined in class) in this question: the Overall accuracy rate ratio between females and males, the disparate impact between females and males, the statistical parity between females and males, and the predictive equality as well as equal opportunity between females and males (collectively these last two comprise equalized odds).  Set a reasonable $\epsilon$ each time and then comment on which (if any) of these five criteria are met.  


```{r}
#Student Input
acc_male <- (4+93)/(4+93+4+28)
acc_female <- (59+4)/(59+4+15+2)
OACC <- acc_female/acc_male

DI <- (59+2)/(4+28)

SP <- (59/(59+2)) - (4/(4+28))

FP_male <- 4/(4+93)
FP_female <- 15/(15+4)
TP_male <- 4/(4+28)
TP_female <- 59/(59+2)

PE <- FP_female - FP_male
EO <- TP_female - TP_male

ep1 <- 0.1
ep2 <- 0.05
ep3 <- 0.2

OACC_fair <- abs(OACC - 1) > ep3
DI_fair <- DI < 1-ep1
SP_fair <- abs(SP) > ep3
PE_fair <- abs(PE) > ep3
EO_fair <- abs(EO) > ep3

list(OACC_fair, DI_fair, SP_fair, PE_fair, EO_fair)

```

The criteria for statistical parity, predictive equality, and equal opportunity are met. The criteria for overall accuracy and disparate impact is not met.  

It is always important for us to interpret our results in light of the original data and the context of the analysis.  In this case, it is relevant that we are analyzing a historical event post-facto and any disparities across demographics identified are unlikely to be replicated.  So even though our model fails numerous of the statistical fairness criteria, I would argue we need not worry that our model could be misused to perpetuate discrimination in the future.  After all, this model is likely not being used to prescribe a preferred method of treatment in the future.  


#

Even so, provide a *philosophical* notion of justice or fairness that may have motivated the Titanic survivors to act as they did. Spell out what this philosophical notion or principle entails?

The argument of equality v equity could be a consideration for the motivation of the Titanic survivors (and non-survivors), which feeds into the believes of Justice as Fairness as seen by John Rawls. The argument of equality v equity stems from need, with each individual getting resources porportional to their need. This would result in more equal opportunities and an efficient use of resources, yet the consideration of what is efficient is questioned, along with scenarios of a lack of resources or luck. Such ideas align with Rawls and Justice as Fairness, with Rawls being a supporter of the Difference Principle. This states that if differences exist, resources are allocated to protect the most vulnerable. This in turns brings up questions such as who is vulnerable and the "veil of ignorance", where one can strip themself of identity and decide resource allocation in such a state of ignorance. When applying this in the case of the Titanic survivors, the ideas of providing resources to the vulnerable could be interpreted as such resources being allocated to females (view of equity as well), which could contribute to their higher rates of survival compared to men. If we look at the survival rates among males and females separately, Justice through Merit could be considered, where resources are allcoated individually according to values of merit. For example, the 4 males who survived from the above confusion matrix could have been deemed more "merit-worthy" compared to the other males, which could have been a factor for their survival against the other males.


